# When and How CNN and GAN Generalize to Out-of-Distribution Category-Viewpoint Combinations

## Description of Project
From the paper “When and How CNNs Generalize to Out-Of-Distribution Category-Viewpoint Combinations”, the authors investigated when and how OOD generalization can be by evaluating CNNs trained to classify both object category and 3D viewpoint on OOD combinations, and identified the neural mechanisms that facilitate such OOD generalization. Recent works suggest that CNNs can hardly to generalize OOD category-viewpoint combinations


In the first part of the experiments, different CNNs architectures and different category-viewpoint architectures are tried to explore their performance of Out-Of-Distribution Category-Viewpoint Generalization on MNIST – Rotation dataset (MNIST-Position and MNIST-Scale dataset). MNIST-Position was created by placing MNIST images into one of nine possible locations in an empty 3-by-3 grid. Images are resized to one of nine possible sizes followed by zero-padding. Images of the digit 9 were left out in both these datasets, ensuring nine categories and nine viewpoints classes (total of 81 category- viewpoint combinations). Total 5 different kinds of CNN architectures are tried: Resnet 18, Resnet 34, Resnet 50, inception V3, Xception. For those CNN architectures, we also tried ‘Separate’, ‘Shared’, and different ‘Split’ architectures for category and viewpoint. Run CNN_mnist.ipynb


In the second part of the experiments, different Generative Adversarial Network (GAN) architectures and different category-viewpoint architectures are tried to explore their performance of Out-Of-Distribution Category Viewpoint Generalization on MNIST - Rotation datasets and Biased-Cars dataset. The inspiration and motivation of trying GANs on OOD problem is that, during the training process of GANs networks, the generator may generate images which category and viewpoint combination are out of the distribution of the trainset, and then the discriminator will then learn from these out of distribution category and viewpoint combinations from the images generated by the generator. This fact may make the GANs more robust when dealing with the OOD problem. Run GAN_mnist_OOD/GAN_mnist.ipynb and GAN_biasedcar_OOD/GAN_biased_car.ipynb


## Description of Repository

## Example commands to execute the code 

## Results (including charts/tables) and observations  
### Evaluation Criteria
We will use the geometric mean of category and viewpoint classification accuracy as mentioned in the original paper of “When and How CNNs Generalize to Out-Of-Distribution Category-Viewpoint Combinations” to evaluate the OOD generalization of different CNN and GAN architectures.

### MNIST-Rotation Dataset
In the first part of our experiments, different CNNs architectures are tried to explore their performance of Out-Of-Distribution Category-Viewpoint Generalization on MNIST–Rotation dataset (MNIST- Position and MNIST-Scale dataset). MNIST-Rotation was created by placing MNIST images into one of nine possible locations in an empty 3-by-3 grid. Images are resized to one of nine possible sizes followed by zero-padding. Images of the digit 9 were left out in both these datasets, ensuring nine categories and nine viewpoint classes (total of 81 category- viewpoint combinations). We tried ‘Separate’ and ‘Shared’ architectures for category and viewpoint. 
![Alt text](/Diagrams/2.png?raw=true)
|:--:| 
| *Figure 1. Different CNN Performances on MNIST-Rotation set(Separate and Shared)* |

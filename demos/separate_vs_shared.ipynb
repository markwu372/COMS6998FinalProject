{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6dc316f",
   "metadata": {
    "id": "r0Gjg0FG3Lh8"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Spandan-Madan/generalization_to_OOD_category_viewpoint_cominations/blob/main/demos/separate_vs_shared.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e6bdfe",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "\n",
    "This demo shows the impact of parameter sharing on out-of-distribution generalization. Specifically, we show how the `SHARED` and `SEPARATE` architectures compare.\n",
    "\n",
    "As shown below, the `SHARED` architecture enforces parameter sharing between the two tasks (category prediction and viewpoint prediction), and the same weights are learned for all convolutional layers for both tasks. These are followed by two task specific fully connected layers for prediction. On the other hand, the `SEPARATE` architecture does not enforce any parameter sharing - all layers are learned separately for the two tasks.\n",
    "\n",
    "As described in the paper, our results show that while `SEPARATE` architecture can perform marginally worse on in-distribution combinations, they perform significantly better on out-of-distribution combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dc73b4",
   "metadata": {},
   "source": [
    "`SHARED`             |  `SEPARATE`\n",
    ":-------------------------:|:-------------------------:\n",
    "![](../docs/images/Shared.png)  |  ![](../docs/images/Separate.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-programmer",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQAmV64ViCpP",
    "outputId": "17696cd0-553c-46bd-a5e2-76cbe592b9c7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def create_folder(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38918b8c",
   "metadata": {},
   "source": [
    "If running on google colab, the below code does the following:\n",
    "- clone repo\n",
    "- set up necessary folders\n",
    "- download MNIST Rotation Dataset at appropriate place\n",
    "- unzip MNIST Rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b4a66",
   "metadata": {},
   "source": [
    "#### If you're not running on colab, please follow download instructions to get the mnist_rotaiton dataset using:\n",
    "\n",
    "```\n",
    "cd utils\n",
    "bash download_mnist_rotation.sh\n",
    "```\n",
    "\n",
    "#### If not using google colab, please proceed below only after downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-explorer",
   "metadata": {
    "id": "3TDIbS5ziEyi"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Cloning code base to colab....')\n",
    "    !git clone https://github.com/Spandan-Madan/generalization_to_OOD_category_viewpoint_cominations.git\n",
    "    !cd generalization_to_OOD_category_viewpoint_cominations/utils && bash download_mnist_rotation.sh\n",
    "    CODE_ROOT = \"generalization_to_OOD_category_viewpoint_cominations/\"\n",
    "else:\n",
    "    CODE_ROOT = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-mozambique",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hairy-growing",
    "outputId": "1bbc681b-bff8-4012-9e02-1be8c768c604"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from PIL import ImageFile\n",
    "import random\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import argparse\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('%s/res/'%CODE_ROOT)\n",
    "from models.models import get_model\n",
    "from loader.loader import get_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-picture",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "european-influence",
    "outputId": "8fc8e967-2579-44f7-8e49-a5e5d48f9e84"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_palette(\"Set1\", 8, .75)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-craps",
   "metadata": {
    "id": "suspected-fever"
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = 'mnist_rotation_six_by_nine'\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 200\n",
    "ARCH = 'LATE_BRANCHING_COMBINED'\n",
    "\n",
    "image_transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "\n",
    "GPU = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-thickness",
   "metadata": {
    "id": "judicial-simpson",
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = (10,10,10,10)\n",
    "loader_new = get_loader('multi_attribute_loader_file_list_mnist_rotation')\n",
    "\n",
    "file_list_root = '%s/dataset_lists/mnist_rotation_lists/'%CODE_ROOT\n",
    "att_path = '%s/dataset_lists/combined_attributes.p'%CODE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-tuner",
   "metadata": {
    "id": "blind-classroom"
   },
   "outputs": [],
   "source": [
    "shuffles = {'train':True,'val':True,'test':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-assignment",
   "metadata": {
    "id": "UGTQbDPvmn_G"
   },
   "outputs": [],
   "source": [
    "data_dir = '%s/data/'%CODE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-stage",
   "metadata": {
    "id": "through-competition"
   },
   "outputs": [],
   "source": [
    "file_lists = {}\n",
    "dsets = {}\n",
    "dset_loaders = {}\n",
    "dset_sizes = {}\n",
    "for phase in ['train','val','test']:\n",
    "    file_lists[phase] = \"%s/%s_list_%s.txt\"%(file_list_root,phase,DATASET_NAME)\n",
    "    dsets[phase] = loader_new(file_lists[phase],att_path, image_transform, data_dir)\n",
    "    dset_loaders[phase] = torch.utils.data.DataLoader(dsets[phase], batch_size=BATCH_SIZE, shuffle = shuffles[phase], num_workers=2,drop_last=True)\n",
    "    dset_sizes[phase] = len(dsets[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-praise",
   "metadata": {
    "id": "wrong-allowance"
   },
   "outputs": [],
   "source": [
    "multi_losses = [nn.CrossEntropyLoss(),nn.CrossEntropyLoss(),nn.CrossEntropyLoss(),nn.CrossEntropyLoss()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-press",
   "metadata": {
    "id": "killing-cause"
   },
   "outputs": [],
   "source": [
    "def weight_scheduler(epoch_num, task):\n",
    "    if task == 'shared':\n",
    "        return [0.0,1.0,0.0,1.0]\n",
    "    elif task == 'viewpoint':\n",
    "        return [0.0,1.0,0.0,0.0]\n",
    "    elif task == 'category':\n",
    "        return [0.0,0.0,0.0,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-union",
   "metadata": {
    "id": "civil-bleeding"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, task, optimizer):\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    phase = 'train'\n",
    "    \n",
    "    weights = weight_scheduler(epoch, task)\n",
    "    iters = 0\n",
    "    phase_epoch_corrects = [0,0,0,0]\n",
    "    phase_epoch_loss = 0\n",
    "    \n",
    "    for data in tqdm(dset_loaders[phase]):\n",
    "        inputs, labels_all, paths = data\n",
    "        inputs = Variable(inputs.float().cuda())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model_outs = model(inputs)\n",
    "        calculated_loss = 0\n",
    "        batch_corrects = [0,0,0,0]\n",
    "        \n",
    "        for i in range(4):\n",
    "            labels = labels_all[:,i]\n",
    "            if GPU:\n",
    "                labels = Variable(labels.long().cuda())\n",
    "            loss = multi_losses[i]\n",
    "            outputs = model_outs[i]\n",
    "            calculated_loss += weights[i] * loss(outputs,labels)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            batch_corrects[i] = torch.sum(preds == labels.data)\n",
    "            phase_epoch_corrects[i] += batch_corrects[i]\n",
    "\n",
    "        \n",
    "        phase_epoch_loss += calculated_loss\n",
    "        calculated_loss.backward()\n",
    "        optimizer.step()\n",
    "        iters += 1\n",
    "    epoch_loss = phase_epoch_loss/dset_sizes[phase]\n",
    "    # print('Train loss:%s'%epoch_loss)\n",
    "    epoch_accs = [float(i)/dset_sizes[phase] for i in phase_epoch_corrects]\n",
    "\n",
    "    if task == 'shared':\n",
    "        epoch_gm = np.sqrt(epoch_accs[1] * epoch_accs[3])\n",
    "    elif task == 'viewpoint':\n",
    "        epoch_gm = epoch_accs[1]\n",
    "    elif task == 'category':\n",
    "        epoch_gm = epoch_accs[3]\n",
    "    \n",
    "    return model, epoch_loss, epoch_gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-binary",
   "metadata": {
    "id": "protecting-majority"
   },
   "outputs": [],
   "source": [
    "def test_epoch(model, best_model, best_test_loss, best_test_gm, task):\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "    phase = 'val'\n",
    "    weights = weight_scheduler(epoch, task)\n",
    "    iters = 0\n",
    "    phase_epoch_corrects = [0,0,0,0]\n",
    "    phase_epoch_loss = 0\n",
    "    \n",
    "    for data in tqdm(dset_loaders[phase]):\n",
    "        inputs, labels_all, paths = data\n",
    "        inputs = Variable(inputs.float().cuda())\n",
    "        model_outs = model(inputs)\n",
    "        calculated_loss = 0\n",
    "        batch_corrects = [0,0,0,0]\n",
    "        \n",
    "        for i in range(4):\n",
    "            labels = labels_all[:,i]\n",
    "            if GPU:\n",
    "                labels = Variable(labels.long().cuda())\n",
    "            loss = multi_losses[i]\n",
    "            outputs = model_outs[i]\n",
    "            calculated_loss += weights[i] * loss(outputs,labels)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            batch_corrects[i] = torch.sum(preds == labels.data)\n",
    "            phase_epoch_corrects[i] += batch_corrects[i]\n",
    "\n",
    "\n",
    "        phase_epoch_loss += calculated_loss\n",
    "        iters += 1\n",
    "    epoch_loss = phase_epoch_loss/dset_sizes[phase]\n",
    "    # print('Test loss:%s'%epoch_loss)\n",
    "    epoch_accs = [float(i)/dset_sizes[phase] for i in phase_epoch_corrects]\n",
    "    \n",
    "    if task == 'shared':\n",
    "        epoch_gm = np.sqrt(epoch_accs[1] * epoch_accs[3])\n",
    "    elif task == 'viewpoint':\n",
    "        epoch_gm = epoch_accs[1]\n",
    "    elif task == 'category':\n",
    "        epoch_gm = epoch_accs[3]\n",
    "    \n",
    "    if epoch_loss < best_test_loss:\n",
    "        best_model = model\n",
    "        best_test_loss = epoch_loss\n",
    "        best_test_gm = epoch_gm\n",
    "    \n",
    "    return best_model, epoch_loss, epoch_gm, best_test_loss, best_test_gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unseen_test_epoch(model, task):\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "    phase = 'test'\n",
    "\n",
    "    weights = weight_scheduler(epoch, task)\n",
    "    iters = 0\n",
    "    phase_epoch_corrects = [0,0,0,0]\n",
    "    phase_epoch_loss = 0\n",
    "    \n",
    "    for data in tqdm(dset_loaders[phase]):\n",
    "        inputs, labels_all, paths = data\n",
    "        inputs = Variable(inputs.float().cuda())\n",
    "        model_outs = model(inputs)\n",
    "        calculated_loss = 0\n",
    "        batch_corrects = [0,0,0,0]\n",
    "        \n",
    "        for i in range(4):\n",
    "            labels = labels_all[:,i]\n",
    "            if GPU:\n",
    "                labels = Variable(labels.long().cuda())\n",
    "            loss = multi_losses[i]\n",
    "            outputs = model_outs[i]\n",
    "            calculated_loss += weights[i] * loss(outputs,labels)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            batch_corrects[i] = torch.sum(preds == labels.data)\n",
    "            phase_epoch_corrects[i] += batch_corrects[i]\n",
    "\n",
    "\n",
    "        phase_epoch_loss += calculated_loss\n",
    "        iters += 1\n",
    "    epoch_loss = phase_epoch_loss/dset_sizes[phase]\n",
    "    epoch_accs = [float(i)/dset_sizes[phase] for i in phase_epoch_corrects]\n",
    "    \n",
    "    if task == 'shared':\n",
    "        epoch_gm = np.sqrt(epoch_accs[1] * epoch_accs[3])\n",
    "    elif task == 'viewpoint':\n",
    "        epoch_gm = epoch_accs[1]\n",
    "    elif task == 'category':\n",
    "        epoch_gm = epoch_accs[3]\n",
    "    \n",
    "    return epoch_loss, epoch_gm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-glossary",
   "metadata": {
    "id": "TPj0Krwrz4Or"
   },
   "source": [
    "Separate vs Shared Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-triumph",
   "metadata": {
    "id": "AVgqCD81miDO"
   },
   "outputs": [],
   "source": [
    "models = {} \n",
    "models['shared']= get_model(ARCH,NUM_CLASSES)\n",
    "models['viewpoint']= get_model(ARCH,NUM_CLASSES)\n",
    "models['category']= get_model(ARCH,NUM_CLASSES)\n",
    "\n",
    "models['shared'].cuda();\n",
    "models['viewpoint'].cuda();\n",
    "models['category'].cuda();\n",
    "\n",
    "best_models = {}\n",
    "best_models['shared'] = models['shared']\n",
    "best_models['viewpoint'] = models['viewpoint']\n",
    "best_models['category'] = models['category']\n",
    "\n",
    "best_test_loss = 100\n",
    "best_test_gm = 0\n",
    "\n",
    "all_train_gms = {}\n",
    "all_train_gms['shared'] = [0]\n",
    "all_train_gms['separate'] = [0]\n",
    "\n",
    "all_test_gms = {}\n",
    "all_test_gms['shared'] = [0]\n",
    "all_test_gms['separate'] = [0]\n",
    "\n",
    "all_unseen_test_gms = {}\n",
    "all_unseen_test_gms['shared'] = [0]\n",
    "all_unseen_test_gms['separate'] = [0]\n",
    "\n",
    "optimizers = {}\n",
    "optimizers['shared'] = optim.Adam(models['shared'].parameters(), lr=0.001)\n",
    "optimizers['viewpoint'] = optim.Adam(models['viewpoint'].parameters(), lr=0.001)\n",
    "optimizers['category'] = optim.Adam(models['category'].parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('xtick', labelsize=14) \n",
    "plt.rc('ytick', labelsize=14) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-difference",
   "metadata": {
    "id": "Fi_v4pE22eDi"
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    train_gm_separate = 1\n",
    "    test_gm_separate = 1\n",
    "    unseen_test_gm_separate = 1\n",
    "\n",
    "    for TASK in ['viewpoint','category','shared']:\n",
    "        print('Epoch: %s, Task: %s'%(epoch,TASK))\n",
    "        print('---------')\n",
    "        models[TASK], train_loss, train_gm = train_epoch(models[TASK], TASK, optimizers[TASK])\n",
    "        best_models[TASK], test_loss, test_gm, best_test_loss, best_test_gm = test_epoch(models[TASK], best_models[TASK], best_test_loss, best_test_gm, TASK)\n",
    "        unseen_test_loss, unseen_test_gm = unseen_test_epoch(models[TASK], TASK)\n",
    "\n",
    "        if TASK != 'shared':\n",
    "            train_gm_separate = train_gm_separate * train_gm\n",
    "            test_gm_separate = test_gm_separate * test_gm\n",
    "            unseen_test_gm_separate = unseen_test_gm_separate * test_gm\n",
    "\n",
    "    all_train_gms['separate'].append(np.sqrt(train_gm_separate))\n",
    "    all_test_gms['separate'].append(np.sqrt(test_gm_separate))\n",
    "    all_unseen_test_gms['separate'].append(np.sqrt(unseen_test_gm_separate))\n",
    "    all_train_gms['shared'].append(train_gm)\n",
    "    all_test_gms['shared'].append(test_gm)\n",
    "    all_unseen_test_gms['shared'].append(np.sqrt(unseen_test_gm))\n",
    "    \n",
    "    clear_output()\n",
    "    print('Epoch: %s'%epoch)\n",
    "    print('---------')\n",
    "    \n",
    "    line_labels = [\"Separate\", \"Shared\"]\n",
    "\n",
    "    fig,ax = plt.subplots(1, 3, figsize=(20,6))\n",
    "    l1 = ax[0].plot(all_train_gms['separate'], color = 'blue', marker = 'o', markersize=5)[0]\n",
    "    l2 = ax[0].plot(all_train_gms['shared'], color = 'red', marker = 'o', markersize=5)[0]\n",
    "    ax[0].set_title('Train Accuracy', fontsize=12)\n",
    "    ax[0].set_ylim(0,1.05)\n",
    "\n",
    "    ax[1].plot(all_test_gms['separate'], color = 'blue', marker = 'o', markersize=5)\n",
    "    ax[1].plot(all_test_gms['shared'], color = 'red', marker = 'o', markersize=5)\n",
    "    ax[1].set_title('Test Accuracy on Seen \\n Category-Viewpoint Combinations', fontsize=12)\n",
    "    ax[1].set_ylim(0,1.05)\n",
    "\n",
    "    ax[2].plot(all_unseen_test_gms['separate'], color = 'blue', marker = 'o', markersize=5)\n",
    "    ax[2].plot(all_unseen_test_gms['shared'], color = 'red', marker = 'o', markersize=5)\n",
    "    ax[2].set_ylim(0,1.05)\n",
    "    ax[2].set_title('Test Accuracy on Unseen \\n Category-Viewpoint Combinations', fontsize=12)\n",
    "    fig.legend([l1, l2],     # The line objects\n",
    "            labels=line_labels,   # The labels for each line\n",
    "            loc=\"center right\",   # Position of legend\n",
    "            borderaxespad=0.2,    # Small spacing around legend box\n",
    "            prop={\"size\":20})\n",
    "    plt.subplots_adjust(right=0.85)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-blair",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "separate_vs_shared.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "generalization_to_ood",
   "language": "python",
   "name": "generalization_to_ood"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
